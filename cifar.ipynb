{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py\n",
    "\n",
    "!wget -qO- https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz | tar xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from image_utils import make_image\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "  with open(file, 'rb') as fo:\n",
    "    dict = pickle.load(fo, encoding='bytes')\n",
    "  return dict\n",
    "\n",
    "def reshape_cifar_pixels(pxs):\n",
    "  return list(zip(pxs[:1024], pxs[1024:2048], pxs[2048:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = unpickle(\"./cifar-10-batches-py/data_batch_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  display(make_image(reshape_cifar_pixels(res[b'data'][i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD16UcVnzJzWjJ0IrMv7y1slD3M8cKscAu2M1upGEoXKcydeKoSpWgJYriMSQyLIh5DKcgiq0i81qpGXKbSapa3LYhdnb0VCf6VxnirxBYyO1v9qMIhO2QyRDbk8cEj61HbTpCHZtRW3foInkZQ3vnoKo3erWck3l3E2SCR8yeYp+hAINcbetjq1sa2gajDBpki3TwwyiVxjeDuXPyn24xV2TU7HtdQ/wDfYrk3uLK5kEayRl3wqkAg/rWhF4H1O4tBcLNbqG+6u/O6tFKNiGpH/9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Extract all images from the dataset\n",
    "all_images = res[b'data']  # Shape: (10000, 3072)\n",
    "\n",
    "# Step 2: Reshape into (10000, 32, 32, 3) for R, G, B\n",
    "# CIFAR-10 stores 1024 R, 1024 G, 1024 B values per image\n",
    "reshaped_images = all_images.reshape(-1, 3, 1024).transpose(0, 2, 1).reshape(-1, 32, 32, 3)\n",
    "\n",
    "\n",
    "image_rgb = reshaped_images[100] #put in the index of image desired\n",
    "img = Image.fromarray(image_rgb.astype('uint8'))  # Convert to an image\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 pixels (R, G, B): [[59, 62, 63], [43, 46, 45], [50, 48, 43], [68, 54, 42], [98, 73, 52], [119, 91, 63], [139, 107, 75], [145, 110, 80], [149, 117, 89], [149, 120, 93]]\n",
      "Total number of pixels: 1024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pixel_values = image_rgb.reshape(-1, 3).tolist() #just make it into list\n",
    "\n",
    "print(\"First 10 pixels (R, G, B):\", pixel_values[:10]) #printing pixel values (first 10 pixels)\n",
    "print(\"Total number of pixels:\", len(pixel_values)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize the image to a larger image for visualization (original size is 32 x 32)(pixelated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_rgb = reshaped_images[0]\n",
    "\n",
    "\n",
    "img = Image.fromarray(image_rgb.astype('uint8'))\n",
    "\n",
    "# Step 3: Resize the image (e.g., scale to 256x256 for better visibility)\n",
    "larger_img = img.resize((256, 256), Image.NEAREST)  # Use NEAREST to keep pixel style\n",
    "\n",
    "# Step 4: Display the resized image\n",
    "larger_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saturated the Image below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDiNHsJ7GBpGkcyuTncxP5VcuL77Kd1xNIN6jgueTV/Vp47VA4jQsW2qBwM1a0rwjH4guoJrlzFJOhaGF+gUYCn8TmvKcm3d9T00klZdDJjv9k5t51nSUjdtbI7defan3+pXlrHsjE0rYyNr9vxrtb/AOHEsiyJMj3FyUxEWfbg/wBa5Wa1kspWtbgbZYTsYHsRxQmtGN8uyZLaQ2tzqMX9oiQ2iS732KC3XoP89K7a+1ZreS71HT7WJUCxJA7Dd5arwRj/ADyawLjR5DdPNYFmjDElAD61UN5qkKypvmUMR8u0jkcVjTrKashuKubdp4tljvlu9UeSeJPmUhgu1/b0HasG6ln1fWnkhZDb3M2UV+4J5qlOiiIGeLeM/MhBIz649afFqLRWuqtZWUs1xBCixkqQihjg49wKc1KasZyjbY//2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDC06xn0iIYb76sBvYvyTya1GntlhczyqC0YK+Y5BPuAKk1NotM2fujIPMAdsfL/wDW+lT6b4btPEmySfVWtrmVmMFtIgLeVn5T9OtfCVK0ZL21V6PqfqfNRp0lKS5YLTRdvJFCLxJFBbTWrNLNGP8AVkDbu/M5FJNqUjw/uYZiZBlcMa6X/hVflR3T/bfPcI32ePGwFsHG48/pWNNY6np6PbS2rw+VhTySvAHIJ7VlCvhaj/cu7+4mnicFVl+4d31vp+BHYxWGoals1FpTFHufdFyXGewPGPrXXNqsRuL7V7W1jdhHGkLSJwiqcEDH1/lVy98IWF6n23R3SLemDEhxFL9SOVPrj06Vx902p+HluLSQXMcrgPyQ0YPYKR1GPWuRVKeLfuvVaWfrqcCqUsc/ceq05Xp1V/yO6h8SQ28Ek07yOxUMw4wnr9BWxH9pmZXYwtbyL8yEc4Pp/hzXkNjM1x/o1yYpGYB2iDZOev3T3HXFdmfGDro2qSWvmXFxZwRkZj2oMttJyByRkE9uPrXHisvcWlTV2/1skcOMyqUGlSV23+dkvxP/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_rgb = reshaped_images[0]\n",
    "img = Image.fromarray(image_rgb.astype('uint8'))  \n",
    "img.show()\n",
    "\n",
    "\n",
    "\n",
    "image_rgb = reshaped_images[0]\n",
    "pixels = np.array(image_rgb, dtype=np.float32)  # using float becasue it was overflow before\n",
    "sat_pixels = []\n",
    "\n",
    "\n",
    "saturation_factor = 22.0 #22--> 2200%\n",
    "for r, g, b in pixels.reshape(-1, 3): \n",
    "    avg = (r + g + b) / 3 #i beleive avg is grayscale??\n",
    "    \n",
    "    new_r = avg + (r - avg) * saturation_factor\n",
    "    new_g = avg + (g - avg) * saturation_factor\n",
    "    new_b = avg + (b - avg) * saturation_factor\n",
    "    \n",
    "\n",
    "    sat_pixels.append((min(255, max(0, new_r)), \n",
    "                       min(255, max(0, new_g)), \n",
    "                       min(255, max(0, new_b))))\n",
    "    # making sure in the valid range (0–255)\n",
    "\n",
    "sat_pixels = np.array(sat_pixels).reshape(32, 32, 3).astype('uint8') \n",
    "# i need to reshape it back and converit it to the Unit 8 thing, i serached online and it says i have to do this. \n",
    "\n",
    "\n",
    "#saturated_img = Image.fromarray(sat_pixels) # convert back to PIL, but #this code out the img still works, bet it wrote the memory\n",
    "saturated_img.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im trying to train the model --> there are two models, 1 encoder, 2 decoder, for:\n",
    "\n",
    "Analyzes an image's red pixel intensity:\n",
    "For each input image (e.g., from the CIFAR-10 dataset), the system calculates how \"red\" the image is by examining its red pixel values.\n",
    "Uses the red pixel intensity to reconstruct a heart shape:\n",
    "The red pixel intensity determines the size or intensity of the reconstructed heart shape.\n",
    "Very red image --> Larger or more vibrant heart.\n",
    "Less red image --> Smaller or fainter heart.\n",
    "\n",
    "This involves:\n",
    "\n",
    "Encoder: Encodes an input image by extracting relevant features (e.g., the red pixel intensity).\n",
    "Decoder: Takes the encoded features (e.g., red intensity) and outputs a new image—a heart shape reconstructed based on the red pixel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate red intensity\n",
    "def calculate_red_intensity(image):\n",
    "    # Ensure the input is a 3D tensor (C, H, W)\n",
    "    if len(image.shape) != 3:\n",
    "        raise ValueError(f\"Expected 3D tensor (C, H, W), but got {image.shape}\") #unfamiliar with raise, practicing\n",
    "\n",
    "    red_channel = image[0, :, :]\n",
    "    \n",
    "    # Calculate total and normalized red intensity\n",
    "    total_red = red_channel.sum().item()\n",
    "    max_red = red_channel.numel() * 255\n",
    "    red_intensity = total_red / max_red\n",
    "    return red_intensity\n",
    "\n",
    "\n",
    "\n",
    "def create_heart_image(intensity, size=(32, 32)):\n",
    "    heart_size = int(intensity * size[0] / 2)\n",
    "    heart_img = Image.new(\"RGB\", size, \"black\")\n",
    "    draw = ImageDraw.Draw(heart_img)\n",
    "    draw.polygon([\n",
    "        (size[0] // 2, size[1] // 8),\n",
    "        (size[0] // 8, 7 * size[1] // 8),\n",
    "        (size[0] // 2, size[1] - size[1] // 8),\n",
    "        (7 * size[0] // 8, 7 * size[1] // 8),\n",
    "    ], fill=(int(255 * intensity), 0, 0))\n",
    "    return ToTensor()(heart_img)\n",
    "\n",
    "#drawinf heart shaped based on the intensity of the red colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert images to tensors and make sure size consistency\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32, 32)) \n",
    "])\n",
    "\n",
    "\n",
    "cifar10 = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "# Custom Dataset for Spy Image (base and secret pairs)\n",
    "class SpyImageDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_image, _ = self.dataset[idx]\n",
    "        secret_image, _ = self.dataset[(idx + 1) % len(self.dataset)]  # Use the next image as the secret\n",
    "        return base_image, secret_image\n",
    "\n",
    "# Create train and test datasets\n",
    "spy_dataset = SpyImageDataset(cifar10)\n",
    "train_loader = DataLoader(spy_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Encoder: Embed secret image into the base image\n",
    "class SpyEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpyEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(6, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, base, secret):\n",
    "        x = torch.cat([base, secret], dim=1)  # Concatenate along channel axis\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        encoded = torch.sigmoid(self.conv2(x))  # Output encoded image\n",
    "        return encoded\n",
    "\n",
    "# Decoder: Extract secret image from the encoded image\n",
    "class SpyDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpyDecoder, self).__init__()\n",
    "\n",
    "    def forward(self, encoded_images):\n",
    "        # Ensure the input is a 4D tensor (B, C, H, W)\n",
    "        if len(encoded_images.shape) != 4:\n",
    "            raise ValueError(f\"Expected 4D tensor (B, C, H, W), but got {encoded_images.shape}\")\n",
    "\n",
    "        # Process each image in the batch\n",
    "        heart_images = []\n",
    "        for image in encoded_images:  # Loop through batch\n",
    "            red_intensity = calculate_red_intensity(image)  # Calculate red intensity\n",
    "            heart_image = create_heart_image(red_intensity)  # Create heart image\n",
    "            heart_images.append(heart_image)\n",
    "        \n",
    "        # Stack the heart images to match batch format\n",
    "        return torch.stack(heart_images)\n",
    "\n",
    "# Initialize models\n",
    "encoder = SpyEncoder()\n",
    "decoder = SpyDecoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()))\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ToTensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Forward pass: encode and decode\u001b[39;00m\n\u001b[1;32m      7\u001b[0m encoded_image \u001b[38;5;241m=\u001b[39m encoder(base_image, secret_image)\n\u001b[0;32m----> 8\u001b[0m decoded_secret \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(decoded_secret, secret_image)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[53], line 30\u001b[0m, in \u001b[0;36mSpyDecoder.forward\u001b[0;34m(self, encoded_images)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m encoded_images:  \u001b[38;5;66;03m# Loop through batch\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     red_intensity \u001b[38;5;241m=\u001b[39m calculate_red_intensity(image)  \u001b[38;5;66;03m# Calculate red intensity\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     heart_image \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_heart_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mred_intensity\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Create heart image\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     heart_images\u001b[38;5;241m.\u001b[39mappend(heart_image)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Stack the heart images to match batch format\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 28\u001b[0m, in \u001b[0;36mcreate_heart_image\u001b[0;34m(intensity, size)\u001b[0m\n\u001b[1;32m     21\u001b[0m draw \u001b[38;5;241m=\u001b[39m ImageDraw\u001b[38;5;241m.\u001b[39mDraw(heart_img)\n\u001b[1;32m     22\u001b[0m draw\u001b[38;5;241m.\u001b[39mpolygon([\n\u001b[1;32m     23\u001b[0m     (size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     24\u001b[0m     (size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m7\u001b[39m \u001b[38;5;241m*\u001b[39m size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     25\u001b[0m     (size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     26\u001b[0m     (\u001b[38;5;241m7\u001b[39m \u001b[38;5;241m*\u001b[39m size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m7\u001b[39m \u001b[38;5;241m*\u001b[39m size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m8\u001b[39m),\n\u001b[1;32m     27\u001b[0m ], fill\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m intensity), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mToTensor\u001b[49m()(heart_img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ToTensor' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 2  # Adjust as needed\n",
    "for epoch in range(epochs):\n",
    "    for base_image, secret_image in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass: encode and decode\n",
    "        encoded_image = encoder(base_image, secret_image)\n",
    "        decoded_secret = decoder(encoded_image)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(decoded_secret, secret_image)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print loss every epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 4D tensor (B, C, H, W), but got torch.Size([3, 32, 32])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m decoder \u001b[38;5;241m=\u001b[39m SpyDecoder()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     heart_image \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_image\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass encoded image to decoder\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Visualize the results\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[53], line 24\u001b[0m, in \u001b[0;36mSpyDecoder.forward\u001b[0;34m(self, encoded_images)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoded_images):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Ensure the input is a 4D tensor (B, C, H, W)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoded_images\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 24\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 4D tensor (B, C, H, W), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoded_images\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Process each image in the batch\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     heart_images \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 4D tensor (B, C, H, W), but got torch.Size([3, 32, 32])"
     ]
    }
   ],
   "source": [
    "# Test with a single CIFAR-10 image\n",
    "base_image, _ = spy_dataset[0]  # Use first CIFAR-10 image\n",
    "base_image = base_image.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Use the trained encoder to encode the image (optional if pre-encoded)\n",
    "with torch.no_grad():\n",
    "    encoded_image = encoder(base_image, base_image)  # Use the same image as base and secret for testing\n",
    "\n",
    "# Use the updated decoder to generate the heart image\n",
    "decoder = SpyDecoder()\n",
    "with torch.no_grad():\n",
    "    heart_image = decoder(encoded_image[0])  # Pass encoded image to decoder\n",
    "\n",
    "# Visualize the results\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(base_image.squeeze().permute(1, 2, 0).numpy())\n",
    "plt.title(\"Base Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(heart_image.permute(1, 2, 0).numpy())\n",
    "plt.title(\"Heart Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
